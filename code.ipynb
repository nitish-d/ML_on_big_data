{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/2305B47/BigData_cute\r\n"
     ]
    }
   ],
   "source": [
    "!pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1. Create the Spark Environment  (2M)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "os.environ[\"SPARK_HOME\"] = \"/usr/hdp/current/spark2-client\"\n",
    "os.environ[\"PYLIB\"] = os.environ[\"SPARK_HOME\"] + \"/python/lib\"\n",
    "sys.path.insert(0, os.environ[\"PYLIB\"] + \"/py4j-0.10.4-src.zip\")\n",
    "sys.path.insert(0, os.environ[\"PYLIB\"] + \"/pyspark.zip\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2. Load the required Libraries for Spark Context and Spark Session (2M)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.conf import SparkConf\n",
    "from pyspark import SparkContext\n",
    "from pyspark.sql import SparkSession"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3. Create the Spark Context and Spark Session (2M)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark = SparkSession.builder\\\n",
    "    .appName(\"SparkML\")\\\n",
    "    .master('local[*]')\\\n",
    "    .enableHiveSupport()\\\n",
    "    .config('spark.sql.warehouse.dir', 'hdfs://bigdata:8020/user/chaithanyas/spark-warehouse')\\\n",
    "    .getOrCreate()\n",
    "sc = spark.sparkContext"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4. Load the libraries for schema definition in Pyspark (2M)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.types import *\n",
    "from pyspark.sql.functions import *\n",
    "\n",
    "from pyspark.sql.functions import isnan, when, count, col, countDistinct"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Problem Statement:\n",
    "* This data was extracted from the census bureau database.The task is to classify the records based on the income field.Incomes have been binned at the 50K level to present a binary classification problem.The instance_weight attribute should not be used in the classifier. All the other attributes and their description are givn below.\n",
    "\n",
    "#### Description of the Attributes\n",
    "* **age**: continuous.\n",
    "* **class of worker**: Not in universe, Federal government, Local government, Never worked, Private, Self-employed- incorporated, Self-employed-not incorporated, State government, Without pay.\n",
    "* **detailed industry recode**: 0, 40, 44, 2, 43, 47, 48, 1, 11, 19, 24, 25, 32, 33, 34, 35, 36, 37, 38, 39, 4, 42, 45, 5, 15, 16, 22, 29, 31, 50, 14, 17, 18, 28, 3, 30, 41, 46, 51, 12, 13, 21, 23, 26, 6, 7, 9, 49, 27, 8, 10, 20.\n",
    "* **detailed occupation recode** : 0, 12, 31, 44, 19, 32, 10, 23, 26, 28, 29, 42, 40, 34, 14, 36, 38, 2, 20, 25, 37, 41, 27, 24, 30, 43, 33, 16, 45, 17, 35, 22, 18, 39, 3, 15, 13, 46, 8, 21, 9, 4, 6, 5, 1, 11, 7.\n",
    "* **education**: Children, 7th and 8th grade, 9th grade, 10th grade, High school graduate, 11th grade, 12th grade no diploma, 5th or 6th grade, Less than 1st grade, Bachelors degree(BA AB BS), 1st 2nd 3rd or 4th grade, Some college but no degree, Masters degree(MA MS MEng MEd MSW MBA), Associates degree-occup /vocational, Associates degree-academic program, Doctorate degree(PhD EdD), Prof school degree (MD DDS DVM LLB JD).\n",
    "* **wage per hour**: continuous.\n",
    "* **enroll in edu inst last wk**: Not in universe, High school, College or university.\n",
    "* **marital stat**: Never married, Married-civilian spouse present, Married-spouse absent, Separated, Divorced, Widowed, Married-A F spouse present.\n",
    "* **major industry code**: Not in universe or children, Entertainment, Social services, Agriculture, Education, Public administration, Manufacturing-durable goods, Manufacturing-nondurable goods, Wholesale trade, Retail trade, Finance insurance and real estate, Private household services, Business and repair services, Personal services except private HH, Construction, Medical except hospital, Other professional services, Transportation, Utilities and sanitary services, Mining, Communications, Hospital services, Forestry and fisheries, Armed Forces.\n",
    "* **major occupation code**: Not in universe, Professional specialty, Other service, Farming forestry and fishing, Sales, Adm support including clerical, Protective services, Handlers equip cleaners etc , Precision production craft & repair, Technicians and related support, Machine operators assmblrs & inspctrs, Transportation and material moving, Executive admin and managerial, Private household services, Armed Forces.\n",
    "* **race**: White, Black, Other, Amer Indian Aleut or Eskimo, Asian or Pacific Islander.\n",
    "* **hispanic origin**: Mexican (Mexicano), Mexican-American, Puerto Rican, Central or South American, All other, Other Spanish, Chicano, Cuban, Do not know, NA.\n",
    "* **sex**: Female, Male.\n",
    "* **member of a labor union**: Not in universe, No, Yes.\n",
    "* **reason for unemployment**: Not in universe, Re-entrant, Job loser - on layoff, New entrant, Job leaver, Other job loser.\n",
    "* **Full or part time employment stat**: Children or Armed Forces, Full-time schedules, Unemployed part- time, Not in labor force, Unemployed full-time, PT for non-econ reasons usually FT, PT for econ reasons usually PT, PT for econ reasons usually FT.\n",
    "* **capital gains**: continuous.\n",
    "* **capital losses**: continuous.\n",
    "* **dividends from stocks**: continuous.\n",
    "* **tax filer stat**: Nonfiler, Joint one under 65 & one 65+, Joint both under 65, Single, Head of household, Joint both 65+.\n",
    "* **region of previous residence**: Not in universe, South, Northeast, West, Midwest, Abroad.\n",
    "* **state of previous residence**: Not in universe, Utah, Michigan, North Carolina, North Dakota, Virginia, Vermont, Wyoming, West Virginia, Pennsylvania, Abroad, Oregon, California, Iowa, Florida, Arkansas, Texas, South Carolina, Arizona, Indiana, Tennessee, Maine, Alaska, Ohio, Montana, Nebraska, Mississippi, District of Columbia, Minnesota, Illinois, Kentucky, Delaware, Colorado, Maryland, Wisconsin, New Hampshire, Nevada, New York, Georgia, Oklahoma, New Mexico, South Dakota, Missouri, Kansas, Connecticut, Louisiana, Alabama, Massachusetts, Idaho, New Jersey.\n",
    "* **detailed household and family stat**: Child <18 never marr not in subfamily, Other Rel <18 never marr child of subfamily RP, Other Rel <18 never marr not in subfamily, Grandchild <18 never marr child of subfamily RP, Grandchild <18 never marr not in subfamily, Secondary individual, In group quarters, Child under 18 of RP of unrel subfamily, RP of unrelated subfamily, Spouse of householder, Householder, Other Rel <18 never married RP of subfamily, Grandchild <18 never marr RP of subfamily, Child <18 never marr RP of subfamily, Child <18 ever marr not in subfamily, Other Rel <18 ever marr RP of subfamily, Child <18 ever marr RP of subfamily, Nonfamily householder, Child <18 spouse of subfamily RP, Other Rel <18 spouse of subfamily RP, Other Rel <18 ever marr not in subfamily, Grandchild <18 ever marr not in subfamily, Child 18+ never marr Not in a subfamily, Grandchild 18+ never marr not in subfamily, Child 18+ ever marr RP of subfamily, Other Rel 18+ never marr not in subfamily, Child 18+ never marr RP of subfamily, Other Rel 18+ ever marr RP of subfamily, Other Rel 18+ never marr RP of subfamily, Other Rel 18+ spouse of subfamily RP, Other Rel 18+ ever marr not in subfamily, Child 18+ ever marr Not in a subfamily, Grandchild 18+ ever marr not in subfamily, Child 18+ spouse of subfamily RP, Spouse of RP of unrelated subfamily, Grandchild 18+ ever marr RP of subfamily, Grandchild 18+ never marr RP of subfamily, Grandchild 18+ spouse of subfamily RP.\n",
    "* **detailed household summary in household**: Child under 18 never married, Other relative of householder, Nonrelative of householder, Spouse of householder, Householder, Child under 18 ever married, Group Quarters- Secondary individual, Child 18 or older.\n",
    "| instance weight: ignore.\n",
    "* **instance weight**: continuous.\n",
    "* **migration code-change in msa**: Not in universe, Nonmover, MSA to MSA, NonMSA to nonMSA, MSA to nonMSA, NonMSA to MSA, Abroad to MSA, Not identifiable, Abroad to nonMSA.\n",
    "* **migration code-change in reg**: Not in universe, Nonmover, Same county, Different county same state, Different state same division, Abroad, Different region, Different division same region.\n",
    "* **migration code-move within reg**: Not in universe, Nonmover, Same county, Different county same state, Different state in West, Abroad, Different state in Midwest, Different state in South, Different state in Northeast.\n",
    "* **live in this house 1 year ago**: Not in universe under 1 year old, Yes, No.\n",
    "* **migration prev res in sunbelt**: Not in universe, Yes, No.\n",
    "* **num persons worked for employer**: continuous.\n",
    "* **family members under 18**: Both parents present, Neither parent present, Mother only present, Father only present, Not in universe.\n",
    "* **country of birth father**: Mexico, United-States, Puerto-Rico, Dominican-Republic, Jamaica, Cuba, Portugal, Nicaragua, Peru, Ecuador, Guatemala, Philippines, Canada, Columbia, El-Salvador, Japan, England, Trinadad&Tobago, Honduras, Germany, Taiwan, Outlying-U S (Guam USVI etc), India, Vietnam, China, Hong Kong, Cambodia, France, Laos, Haiti, South Korea, Iran, Greece, Italy, Poland, Thailand, Yugoslavia, Holand-Netherlands, Ireland, Scotland, Hungary, Panama.\n",
    "* **country of birth mother**: India, Mexico, United-States, Puerto-Rico, Dominican-Republic, England, Honduras, Peru, Guatemala, Columbia, El-Salvador, Philippines, France, Ecuador, Nicaragua, Cuba, Outlying-U S (Guam USVI etc), Jamaica, South Korea, China, Germany, Yugoslavia, Canada, Vietnam, Japan, Cambodia, Ireland, Laos, Haiti, Portugal, Taiwan, Holand-Netherlands, Greece, Italy, Poland, Thailand, Trinadad&Tobago, Hungary, Panama, Hong Kong, Scotland, Iran.\n",
    "* **country of birth self**: United-States, Mexico, Puerto-Rico, Peru, Canada, South Korea, India, Japan, Haiti, El-Salvador, Dominican-Republic, Portugal, Columbia, England, Thailand, Cuba, Laos, Panama, China, Germany, Vietnam, Italy, Honduras, Outlying-U S (Guam USVI etc), Hungary, Philippines, Poland, Ecuador, Iran, Guatemala, Holand-Netherlands, Taiwan, Nicaragua, France, Jamaica, Scotland, Yugoslavia, Hong Kong, Trinadad&Tobago, Greece, Cambodia, Ireland.\n",
    "* **citizenship**: Native- Born in the United States, Foreign born- Not a citizen of U S , Native- Born in Puerto Rico or U S Outlying, Native- Born abroad of American Parent(s), Foreign born- U S citizen by naturalization.\n",
    "* **own business or self employed**: 0, 2, 1.\n",
    "* **fill inc questionnaire for veteran's admin**: Not in universe, Yes, No.\n",
    "* **veterans benefits**: 0, 2, 1.\n",
    "* **weeks worked in year**: continuous.\n",
    "* **year**: 94, 95.\n",
    "\n",
    "* **Income** : -50000 and 50000"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5. Define the schema from the description above (4M)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# bankDataSchema = StructType([\n",
    "#     StructField(\"age\", IntegerType(), True),\n",
    "#     StructField(\"class of worker\", StringType(), True),\n",
    "#     StructField(\"detailed occupation recode\", IntegerType(), True),\n",
    "#     StructField(\"education\", StringType(), True),\n",
    "#     StructField(\"wage per hour\", IntegerType(), True),\n",
    "#     StructField(\"enroll in edu inst last wk\", StringType(), True),\n",
    "#     StructField(\"marital stat\", StringType(), True),\n",
    "#     StructField(\"major industry code\", StringType(), True),        \n",
    "#     StructField(\"major occupation code\", StringType(), True),\n",
    "#     StructField(\"hispanic origin\", StringType(), True),\n",
    "#     StructField(\"race\", StringType(), True),\n",
    "#     StructField(\"sex\", StringType(), True),\n",
    "#     StructField(\"member of a labor union\", StringType(), True),\n",
    "#     StructField(\"reason for unemployment\", StringType(), True),\n",
    "#     StructField(\"Full or part time employment stat\", StringType(), True),\n",
    "#     StructField(\"capital gains\", IntegerType(), True),\n",
    "#     StructField(\"capital losses\", IntegerType(), True),\n",
    "#     StructField(\"dividends from stocks\", IntegerType(), True),\n",
    "#     StructField(\"tax filer stat\", StringType(), True),\n",
    "#     StructField(\"region of previous residence\", StringType(), True),\n",
    "#     StructField(\"capital gains\", IntegerType(), True),\n",
    "#     StructField(\"capital gains\", IntegerType(), True),\n",
    "#     StructField(\"capital gains\", IntegerType(), True),\n",
    "#     StructField(\"capital gains\", IntegerType(), True)])\n",
    "censusDataSchema = StructType([\n",
    "    StructField(\"age\", IntegerType(), True),\n",
    "    StructField(\"class_of_worker\", StringType(), True),\n",
    "    StructField(\"detailed_industry_recode\", IntegerType(), True),\n",
    "    StructField(\"detailed_occupation_recode\", IntegerType(), True),\n",
    "    StructField(\"education\", StringType(), True),\n",
    "    StructField(\"wage_per_hour\", DoubleType(), True),\n",
    "    StructField(\"enroll_inst\", StringType(), True),\n",
    "    StructField(\"marital_stat\", StringType(), True),        \n",
    "    StructField(\"industry_code\", StringType(), True),\n",
    "    StructField(\"occupation_code\", StringType(), True),\n",
    "    StructField(\"race\", StringType(), True),\n",
    "    StructField(\"hispanic_origin\", StringType(), True),\n",
    "    StructField(\"sex\", StringType(), True),\n",
    "    StructField(\"labor_union\", StringType(), True),\n",
    "    StructField(\"reason_unemployment\", StringType(), True),\n",
    "    StructField(\"employment_stat\", StringType(), True),\n",
    "    StructField(\"capital_gains\", DoubleType(), True),\n",
    "    StructField(\"capital_losses\", DoubleType(), True),\n",
    "    StructField(\"dividends\", DoubleType(), True),\n",
    "    StructField(\"tax_filer_stat\", StringType(), True),\n",
    "    StructField(\"region_previous_residence\", StringType(), True),\n",
    "    StructField(\"state_previous_residence\", StringType(), True),\n",
    "    StructField(\"detailed_family_stat\", StringType(), True),\n",
    "    StructField(\"detailed_house_summary\", StringType(), True),\n",
    "    StructField(\"instance_weight\", DoubleType(), True),\n",
    "    StructField(\"migration_code_msa\", StringType(), True),\n",
    "    StructField(\"migration_code_in_reg\", StringType(), True),\n",
    "    StructField(\"migration_code_within_reg\", StringType(), True),\n",
    "    StructField(\"1_year_ago\", StringType(), True),\n",
    "    StructField(\"prev_res_sunbelt\", StringType(), True),\n",
    "    StructField(\"num_persons_worked\", IntegerType(), True),\n",
    "    StructField(\"family_under_18\", StringType(), True),\n",
    "    StructField(\"country_birth_father\", StringType(), True),\n",
    "    StructField(\"country_birth_mother\", StringType(), True),\n",
    "    StructField(\"country_birth_self\", StringType(), True),\n",
    "    StructField(\"citizenship\", StringType(), True),\n",
    "    StructField(\"business_type\", StringType(), True),\n",
    "    StructField(\"fill_questionnaire\", StringType(), True),\n",
    "    StructField(\"veterans_benefits\", StringType(), True),\n",
    "    StructField(\"weeks_worked\", IntegerType(), True),\n",
    "    StructField(\"year\", StringType(), True),\n",
    "    StructField(\"Income\", StringType(), True)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 6. Read the Data from the CSV File (3M)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = spark.read.csv(path='/user/2305B47/BigDataCute/trainData.csv',\n",
    "                      header=False,\n",
    "                      schema=censusDataSchema)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 7.  Read/View Four rows (2M)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+--------------------+------------------------+--------------------------+--------------------+-------------+---------------+--------------------+--------------------+--------------------+-----+---------------+------+---------------+-------------------+--------------------+-------------+--------------+---------+-------------------+-------------------------+------------------------+--------------------+----------------------+---------------+------------------+---------------------+-------------------------+--------------------+----------------+------------------+---------------+--------------------+--------------------+------------------+--------------------+-------------+------------------+-----------------+------------+----+--------+\n",
      "|age|     class_of_worker|detailed_industry_recode|detailed_occupation_recode|           education|wage_per_hour|    enroll_inst|        marital_stat|       industry_code|     occupation_code| race|hispanic_origin|   sex|    labor_union|reason_unemployment|     employment_stat|capital_gains|capital_losses|dividends|     tax_filer_stat|region_previous_residence|state_previous_residence|detailed_family_stat|detailed_house_summary|instance_weight|migration_code_msa|migration_code_in_reg|migration_code_within_reg|          1_year_ago|prev_res_sunbelt|num_persons_worked|family_under_18|country_birth_father|country_birth_mother|country_birth_self|         citizenship|business_type|fill_questionnaire|veterans_benefits|weeks_worked|year|  Income|\n",
      "+---+--------------------+------------------------+--------------------------+--------------------+-------------+---------------+--------------------+--------------------+--------------------+-----+---------------+------+---------------+-------------------+--------------------+-------------+--------------+---------+-------------------+-------------------------+------------------------+--------------------+----------------------+---------------+------------------+---------------------+-------------------------+--------------------+----------------+------------------+---------------+--------------------+--------------------+------------------+--------------------+-------------+------------------+-----------------+------------+----+--------+\n",
      "| 58|Self-employed-not...|                       4|                        34|Some college but ...|          0.0|Not in universe|            Divorced|        Construction|Precision product...|White|      All other|  Male|Not in universe|    Not in universe|Children or Armed...|          0.0|           0.0|      0.0|  Head of household|                    South|                Arkansas|         Householder|           Householder|        1053.55|        MSA to MSA|          Same county|              Same county|                  No|             Yes|                 1|Not in universe|       United-States|       United-States|     United-States|Native- Born in t...|            0|   Not in universe|                2|          52|  94|- 50000.|\n",
      "| 42|             Private|                      34|                         3|Bachelors degree(...|          0.0|Not in universe|Married-civilian ...|Finance insurance...|Executive admin a...|White|      All other|  Male|Not in universe|    Not in universe|Children or Armed...|       5178.0|           0.0|      0.0|Joint both under 65|          Not in universe|         Not in universe|         Householder|           Householder|        1535.86|          Nonmover|             Nonmover|                 Nonmover|                 Yes| Not in universe|                 6|Not in universe|       United-States|       United-States|     United-States|Native- Born in t...|            0|   Not in universe|                2|          52|  94|- 50000.|\n",
      "| 34|             Private|                       4|                        37|Some college but ...|          0.0|Not in universe|Married-civilian ...|        Construction|Machine operators...|White|      All other|  Male|Not in universe|    Not in universe|Children or Armed...|          0.0|           0.0|      0.0|Joint both under 65|          Not in universe|         Not in universe|         Householder|           Householder|        1146.79|          Nonmover|             Nonmover|                 Nonmover|                 Yes| Not in universe|                 6|Not in universe|       United-States|       United-States|     United-States|Native- Born in t...|            0|   Not in universe|                2|          52|  94|- 50000.|\n",
      "| 26|             Private|                      24|                        12|Bachelors degree(...|          0.0|Not in universe|       Never married|Manufacturing-non...|Professional spec...|White|      All other|Female|Not in universe|    Not in universe| Full-time schedules|          0.0|           0.0|      0.0|             Single|          Not in universe|         Not in universe|Nonfamily househo...|           Householder|        2604.91|              null|                 null|                     null|Not in universe u...|            null|                 6|Not in universe|       United-States|       United-States|     United-States|Native- Born in t...|            0|   Not in universe|                2|          52|  95|- 50000.|\n",
      "+---+--------------------+------------------------+--------------------------+--------------------+-------------+---------------+--------------------+--------------------+--------------------+-----+---------------+------+---------------+-------------------+--------------------+-------------+--------------+---------+-------------------+-------------------------+------------------------+--------------------+----------------------+---------------+------------------+---------------------+-------------------------+--------------------+----------------+------------------+---------------+--------------------+--------------------+------------------+--------------------+-------------+------------------+-----------------+------------+----+--------+\n",
      "only showing top 4 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "data.head(4)\n",
    "data.show(4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 8. Inspect the data types of the Columns (2M)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('age', 'int'),\n",
       " ('class_of_worker', 'string'),\n",
       " ('detailed_industry_recode', 'int'),\n",
       " ('detailed_occupation_recode', 'int'),\n",
       " ('education', 'string'),\n",
       " ('wage_per_hour', 'double'),\n",
       " ('enroll_inst', 'string'),\n",
       " ('marital_stat', 'string'),\n",
       " ('industry_code', 'string'),\n",
       " ('occupation_code', 'string'),\n",
       " ('race', 'string'),\n",
       " ('hispanic_origin', 'string'),\n",
       " ('sex', 'string'),\n",
       " ('labor_union', 'string'),\n",
       " ('reason_unemployment', 'string'),\n",
       " ('employment_stat', 'string'),\n",
       " ('capital_gains', 'double'),\n",
       " ('capital_losses', 'double'),\n",
       " ('dividends', 'double'),\n",
       " ('tax_filer_stat', 'string'),\n",
       " ('region_previous_residence', 'string'),\n",
       " ('state_previous_residence', 'string'),\n",
       " ('detailed_family_stat', 'string'),\n",
       " ('detailed_house_summary', 'string'),\n",
       " ('instance_weight', 'double'),\n",
       " ('migration_code_msa', 'string'),\n",
       " ('migration_code_in_reg', 'string'),\n",
       " ('migration_code_within_reg', 'string'),\n",
       " ('1_year_ago', 'string'),\n",
       " ('prev_res_sunbelt', 'string'),\n",
       " ('num_persons_worked', 'int'),\n",
       " ('family_under_18', 'string'),\n",
       " ('country_birth_father', 'string'),\n",
       " ('country_birth_mother', 'string'),\n",
       " ('country_birth_self', 'string'),\n",
       " ('citizenship', 'string'),\n",
       " ('business_type', 'string'),\n",
       " ('fill_questionnaire', 'string'),\n",
       " ('veterans_benefits', 'string'),\n",
       " ('weeks_worked', 'int'),\n",
       " ('year', 'string'),\n",
       " ('Income', 'string')]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 9. Find the Total rows and Columns in the Dataset(2M)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No. of Rows = 99579\n",
      "No. of Columns = 42\n"
     ]
    }
   ],
   "source": [
    "print('No. of Rows = {}'.format(data.count()))\n",
    "print(\"No. of Columns = {}\".format(len(data.columns)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 10. Find the summary Statistics for the numerical attributes (2M)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['age', 'detailed_industry_recode', 'detailed_occupation_recode', 'wage_per_hour', 'capital_gains', 'capital_losses', 'dividends', 'instance_weight', 'num_persons_worked', 'weeks_worked']\n",
      "['class_of_worker', 'education', 'enroll_inst', 'marital_stat', 'industry_code', 'occupation_code', 'race', 'hispanic_origin', 'sex', 'labor_union', 'reason_unemployment', 'employment_stat', 'tax_filer_stat', 'region_previous_residence', 'state_previous_residence', 'detailed_family_stat', 'detailed_house_summary', 'migration_code_msa', 'migration_code_in_reg', 'migration_code_within_reg', '1_year_ago', 'prev_res_sunbelt', 'family_under_18', 'country_birth_father', 'country_birth_mother', 'country_birth_self', 'citizenship', 'business_type', 'fill_questionnaire', 'veterans_benefits', 'year', 'Income']\n"
     ]
    }
   ],
   "source": [
    "CatVar = []\n",
    "NumVar = []\n",
    "def variableSplitting(data):\n",
    "    for c in data.dtypes:\n",
    "        if c[1] == 'string':\n",
    "            CatVar.append(c[0])  \n",
    "        else:\n",
    "            NumVar.append(c[0])\n",
    "        \n",
    "    return NumVar, CatVar\n",
    "(NumVar, CatVar) = variableSplitting(data)\n",
    "print(NumVar)\n",
    "print(CatVar)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+------------------+------------------------+--------------------------+-----------------+------------------+------------------+------------------+------------------+------------------+------------------+\n",
      "|summary|               age|detailed_industry_recode|detailed_occupation_recode|    wage_per_hour|     capital_gains|    capital_losses|         dividends|   instance_weight|num_persons_worked|      weeks_worked|\n",
      "+-------+------------------+------------------------+--------------------------+-----------------+------------------+------------------+------------------+------------------+------------------+------------------+\n",
      "|  count|             99579|                   99579|                     99579|            99579|             99579|             99579|             99579|             99579|             99579|             99579|\n",
      "|   mean| 34.56644473232308|      15.372909950893261|        11.260958635856959|55.66638548288294|443.29279265708635|37.530402996615756| 197.0633065204511|1743.0972726177185|1.9630444169955512| 23.20532441579048|\n",
      "| stddev|22.332816121498283|       18.07790264936059|        14.419862069735315|274.8698275934865| 4758.023857997538| 272.5512452587624|2017.0590464087118| 995.1220593409332|2.3666126944155605|24.404795969846994|\n",
      "|    min|                 0|                       0|                         0|              0.0|               0.0|               0.0|               0.0|             37.87|                 0|                 0|\n",
      "|    max|                90|                      51|                        46|           9800.0|           99999.0|            4608.0|           99999.0|           13911.5|                 6|                52|\n",
      "+-------+------------------+------------------------+--------------------------+-----------------+------------------+------------------+------------------+------------------+------------------+------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "data.select(NumVar).describe().show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 11. Find the missing Values in each Column (2M)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+---------------+------------------------+--------------------------+---------+-------------+-----------+------------+-------------+---------------+----+---------------+---+-----------+-------------------+---------------+-------------+--------------+---------+--------------+-------------------------+------------------------+--------------------+----------------------+---------------+------------------+---------------------+-------------------------+----------+----------------+------------------+---------------+--------------------+--------------------+------------------+-----------+-------------+------------------+-----------------+------------+----+------+\n",
      "|age|class_of_worker|detailed_industry_recode|detailed_occupation_recode|education|wage_per_hour|enroll_inst|marital_stat|industry_code|occupation_code|race|hispanic_origin|sex|labor_union|reason_unemployment|employment_stat|capital_gains|capital_losses|dividends|tax_filer_stat|region_previous_residence|state_previous_residence|detailed_family_stat|detailed_house_summary|instance_weight|migration_code_msa|migration_code_in_reg|migration_code_within_reg|1_year_ago|prev_res_sunbelt|num_persons_worked|family_under_18|country_birth_father|country_birth_mother|country_birth_self|citizenship|business_type|fill_questionnaire|veterans_benefits|weeks_worked|year|Income|\n",
      "+---+---------------+------------------------+--------------------------+---------+-------------+-----------+------------+-------------+---------------+----+---------------+---+-----------+-------------------+---------------+-------------+--------------+---------+--------------+-------------------------+------------------------+--------------------+----------------------+---------------+------------------+---------------------+-------------------------+----------+----------------+------------------+---------------+--------------------+--------------------+------------------+-----------+-------------+------------------+-----------------+------------+----+------+\n",
      "|  0|              0|                       0|                         0|        0|            0|          0|           0|            0|              0|   0|              0|  0|          0|                  0|              0|            0|             0|        0|             0|                        0|                     356|                   0|                     0|              0|             49731|                49731|                    49731|         0|           49731|                 0|              0|                3272|                2961|              1603|          0|            0|                 0|                0|           0|   0|     0|\n",
      "+---+---------------+------------------------+--------------------------+---------+-------------+-----------+------------+-------------+---------------+----+---------------+---+-----------+-------------------+---------------+-------------+--------------+---------+--------------+-------------------------+------------------------+--------------------+----------------------+---------------+------------------+---------------------+-------------------------+----------+----------------+------------------+---------------+--------------------+--------------------+------------------+-----------+-------------+------------------+-----------------+------------+----+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "data.select([count(when(isnan(c) | col(c).isNull(), c)).alias(c) \n",
    "             for c in data.columns]).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 12. Drop the Columns that have missing values more than 20% (3M)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import col\n",
    "\n",
    "for c in data.columns:\n",
    "    if data.select(c).filter(col(c).isNull()).count() > (data.count()*0.20):\n",
    "        data = data.drop(c)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 13. Drop the rows with NA values and work on the remaining dataset(2M)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+---------------+------------------------+--------------------------+---------+-------------+-----------+------------+-------------+---------------+----+---------------+---+-----------+-------------------+---------------+-------------+--------------+---------+--------------+-------------------------+------------------------+--------------------+----------------------+---------------+----------+------------------+---------------+--------------------+--------------------+------------------+-----------+-------------+------------------+-----------------+------------+----+------+\n",
      "|age|class_of_worker|detailed_industry_recode|detailed_occupation_recode|education|wage_per_hour|enroll_inst|marital_stat|industry_code|occupation_code|race|hispanic_origin|sex|labor_union|reason_unemployment|employment_stat|capital_gains|capital_losses|dividends|tax_filer_stat|region_previous_residence|state_previous_residence|detailed_family_stat|detailed_house_summary|instance_weight|1_year_ago|num_persons_worked|family_under_18|country_birth_father|country_birth_mother|country_birth_self|citizenship|business_type|fill_questionnaire|veterans_benefits|weeks_worked|year|Income|\n",
      "+---+---------------+------------------------+--------------------------+---------+-------------+-----------+------------+-------------+---------------+----+---------------+---+-----------+-------------------+---------------+-------------+--------------+---------+--------------+-------------------------+------------------------+--------------------+----------------------+---------------+----------+------------------+---------------+--------------------+--------------------+------------------+-----------+-------------+------------------+-----------------+------------+----+------+\n",
      "|  0|              0|                       0|                         0|        0|            0|          0|           0|            0|              0|   0|              0|  0|          0|                  0|              0|            0|             0|        0|             0|                        0|                       0|                   0|                     0|              0|         0|                 0|              0|                   0|                   0|                 0|          0|            0|                 0|                0|           0|   0|     0|\n",
      "+---+---------------+------------------------+--------------------------+---------+-------------+-----------+------------+-------------+---------------+----+---------------+---+-----------+-------------------+---------------+-------------+--------------+---------+--------------+-------------------------+------------------------+--------------------+----------------------+---------------+----------+------------------+---------------+--------------------+--------------------+------------------+-----------+-------------+------------------+-----------------+------------+----+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# data = data.dropna(how='any', thresh=None, subset=None)\n",
    "data=data.na.drop()\n",
    "data.select([count(when(isnan(c) | col(c).isNull(), c)).alias(c) \n",
    "             for c in data.columns]).show()\n",
    "# data.filter(data.col(\"country_birth_mother\").isNotNull())\n",
    "# data.na.drop([\"country_birth_mother\"])\n",
    "# dropna(how='any', thresh=None, subset=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data.drop(data.instance_weight)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 14. The distribution of income class on education(2M)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+--------+-----+\n",
      "|           education|  Income|count|\n",
      "+--------------------+--------+-----+\n",
      "|          10th grade|- 50000.| 3554|\n",
      "|          10th grade| 50000+.|   33|\n",
      "|          11th grade| 50000+.|   28|\n",
      "|          11th grade|- 50000.| 3299|\n",
      "|12th grade no dip...|- 50000.|  961|\n",
      "|12th grade no dip...| 50000+.|   16|\n",
      "|1st 2nd 3rd or 4t...| 50000+.|    5|\n",
      "|1st 2nd 3rd or 4t...|- 50000.|  864|\n",
      "|    5th or 6th grade|- 50000.| 1528|\n",
      "|    5th or 6th grade| 50000+.|    9|\n",
      "|   7th and 8th grade| 50000+.|   36|\n",
      "|   7th and 8th grade|- 50000.| 3710|\n",
      "|           9th grade| 50000+.|   17|\n",
      "|           9th grade|- 50000.| 2997|\n",
      "|Associates degree...| 50000+.|  211|\n",
      "|Associates degree...|- 50000.| 1887|\n",
      "|Associates degree...|- 50000.| 2379|\n",
      "|Associates degree...| 50000+.|  205|\n",
      "|Bachelors degree(...| 50000+.| 1849|\n",
      "|Bachelors degree(...|- 50000.| 7440|\n",
      "+--------------------+--------+-----+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "data.groupBy(data.education,data.Income).count().orderBy(data.education).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 15. Find the Correlation between  Columns : \"weeks worked in year\" and \"no. of persons worked for employer\" (2M)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7495145872631152"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# from pyspark.ml.stat import Correlation\n",
    "\n",
    "# Correlation.corr(data, \"weeks_worked\", \"num_persons_worked\" )\n",
    "data.stat.corr('weeks_worked', 'num_persons_worked')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 16. Define the schema dict from data type of the Data Frame (2M)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'employment_stat': 'string', 'tax_filer_stat': 'string', 'capital_gains': 'double', 'country_birth_father': 'string', 'detailed_house_summary': 'string', 'Income': 'string', 'sex': 'string', 'year': 'string', 'education': 'string', 'labor_union': 'string', 'citizenship': 'string', 'marital_stat': 'string', 'weeks_worked': 'int', '1_year_ago': 'string', 'occupation_code': 'string', 'industry_code': 'string', 'region_previous_residence': 'string', 'num_persons_worked': 'int', 'detailed_occupation_recode': 'int', 'country_birth_mother': 'string', 'fill_questionnaire': 'string', 'detailed_industry_recode': 'int', 'hispanic_origin': 'string', 'state_previous_residence': 'string', 'capital_losses': 'double', 'dividends': 'double', 'veterans_benefits': 'string', 'country_birth_self': 'string', 'business_type': 'string', 'enroll_inst': 'string', 'wage_per_hour': 'double', 'age': 'int', 'class_of_worker': 'string', 'race': 'string', 'reason_unemployment': 'string', 'detailed_family_stat': 'string', 'family_under_18': 'string'}\n"
     ]
    }
   ],
   "source": [
    "data.dtypes\n",
    "data_dict = dict(data.dtypes)\n",
    "print(data_dict)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 17. Write code to Seperate the columns in Categorical and Numerical attributes using the datatypes dictionary (Not Manual)(2M)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "Cat_Var = []\n",
    "Num_Var = []\n",
    "for key, value in data_dict.iteritems():\n",
    "    if value == 'string':\n",
    "        Cat_Var.append(key)\n",
    "    else :\n",
    "        Num_Var.append(key)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 18. Split the data into train and test (2M)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "66536\n",
      "28657\n"
     ]
    }
   ],
   "source": [
    "(trainingData, testData) = data.randomSplit([0.7, 0.3])\n",
    "print(trainingData.count())\n",
    "print(testData.count())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 19. Cache the train and validation data sets and unpersist data (2M)¶"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[age: int, class_of_worker: string, detailed_industry_recode: int, detailed_occupation_recode: int, education: string, wage_per_hour: double, enroll_inst: string, marital_stat: string, industry_code: string, occupation_code: string, race: string, hispanic_origin: string, sex: string, labor_union: string, reason_unemployment: string, employment_stat: string, capital_gains: double, capital_losses: double, dividends: double, tax_filer_stat: string, region_previous_residence: string, state_previous_residence: string, detailed_family_stat: string, detailed_house_summary: string, 1_year_ago: string, num_persons_worked: int, family_under_18: string, country_birth_father: string, country_birth_mother: string, country_birth_self: string, citizenship: string, business_type: string, fill_questionnaire: string, veterans_benefits: string, weeks_worked: int, year: string, Income: string]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainingData.cache()\n",
    "testData.cache()\n",
    "data.unpersist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 20. Check for the Class balance in the train and test data set (2M)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+-----+\n",
      "|  Income|count|\n",
      "+--------+-----+\n",
      "| 50000+.| 4081|\n",
      "|- 50000.|62455|\n",
      "+--------+-----+\n",
      "\n",
      "+--------+-----+\n",
      "|  Income|count|\n",
      "+--------+-----+\n",
      "| 50000+.| 1705|\n",
      "|- 50000.|26952|\n",
      "+--------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "trainingData.groupBy(trainingData.Income).count().show()\n",
    "\n",
    "testData.groupBy(trainingData.Income).count().show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 21.  Perform the required feature Preprocessing  and create the pipeline for the flow: (10M)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "Cat_Var.remove(\"Income\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.feature import VectorAssembler\n",
    "\n",
    "assembler_Num = VectorAssembler(inputCols=Num_Var, outputCol=\"num_features\")\n",
    "\n",
    "from pyspark.ml.feature import MinMaxScaler\n",
    "\n",
    "min_Max_Scalar = MinMaxScaler(inputCol=\"num_features\", outputCol=\"scaled_num_features\")\n",
    "# Cat_Var.remove('Income')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.feature import OneHotEncoder, StringIndexer, VectorAssembler\n",
    "\n",
    "indexers_Cat = [StringIndexer(inputCol=cat_Var_Name, handleInvalid='keep', outputCol=\"{0}_index\".format(cat_Var_Name)) for cat_Var_Name in Cat_Var ]\n",
    "encoders_Cat = [OneHotEncoder(inputCol=indexer.getOutputCol(), outputCol=\"{0}_vec\".format(indexer.getInputCol())) for indexer in indexers_Cat]\n",
    "assembler_Cat = VectorAssembler(inputCols=[encoder.getOutputCol() for encoder in encoders_Cat], outputCol=\"cat_features\")\n",
    "\n",
    "assembler = VectorAssembler(inputCols=[\"scaled_num_features\", \"cat_features\"], outputCol=\"features\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "indexer_Label = StringIndexer(inputCol=\"Income\", outputCol=\"label\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocessiong_Stages = [assembler_Num]+[min_Max_Scalar]+indexers_Cat+encoders_Cat+[assembler_Cat]+[assembler]+[indexer_Label]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "32"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import gc\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 22. Create the Logistic regression Model(5M)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.classification import LogisticRegression\n",
    "\n",
    "lr = LogisticRegression(maxIter=10, labelCol=\"label\", featuresCol=\"features\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml import Pipeline\n",
    "\n",
    "lr_Pipeline = Pipeline(stages=preprocessiong_Stages+[lr]) \n",
    "\n",
    "lr_Pipeline_model = lr_Pipeline.fit(trainingData)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Print the objective history."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "objectiveHistory:\n",
      "0.230625722838\n",
      "0.19104693132\n",
      "0.150907815599\n",
      "0.145387620438\n",
      "0.140426120397\n",
      "0.137673920945\n",
      "0.135326729591\n",
      "0.132719428186\n",
      "0.12892305362\n",
      "0.126120743824\n",
      "0.125326579264\n"
     ]
    }
   ],
   "source": [
    "# print(\"Coefficients: \" + str(lr_Pipeline_model.stages[-1].coefficients))\n",
    "# print(\"Intercept: \" + str(lr_Pipeline_model.stages[-1].intercept))\n",
    "\n",
    "lr_Summary = lr_Pipeline_model.stages[-1].summary\n",
    "objectiveHistory = lr_Summary.objectiveHistory\n",
    "print(\"objectiveHistory:\")\n",
    "for objective in objectiveHistory:\n",
    "    print(objective)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 23. Answer the following questions (2M)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* What is the train accuracy ?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_predictions_lr = lr_Pipeline_model.transform(trainingData)\n",
    "test_predictions_lr = lr_Pipeline_model.transform(testData)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train accuracy  = 0.951800529037\n"
     ]
    }
   ],
   "source": [
    "train_predictions_lr = lr_Pipeline_model.transform(trainingData)\n",
    "from pyspark.ml.evaluation import MulticlassClassificationEvaluator\n",
    "\n",
    "evaluator = MulticlassClassificationEvaluator(labelCol=\"label\", \n",
    "                                              predictionCol=\"prediction\",\n",
    "                                              metricName=\"accuracy\")\n",
    "\n",
    "predictionAndLabels_train_lr = train_predictions_lr.select(\"prediction\", \"label\")\n",
    "train_accuracy_lr = evaluator.evaluate(predictionAndLabels_train_lr)\n",
    "\n",
    "print(\"Train accuracy  = \" + str(train_accuracy_lr))\n",
    "# test_predictions_lr = lr_Pipeline_model.transform(testData)\n",
    "\n",
    "# test_predictions_lr = lr_Pipeline_model.transform(testData)\n",
    "# predictionAndLabels_test_lr = test_predictions_lr.select(\"prediction\", \"label\")\n",
    "# test_accuracy_lr = evaluator.evaluate(predictionAndLabels_test_lr)\n",
    "\n",
    "# print(\"Test accuracy = \" + str(test_accuracy_lr))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* What is test accuracy?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test accuracy = 0.951983808494\n"
     ]
    }
   ],
   "source": [
    "test_predictions_lr = lr_Pipeline_model.transform(testData)\n",
    "predictionAndLabels_test_lr = test_predictions_lr.select(\"prediction\", \"label\")\n",
    "test_accuracy_lr = evaluator.evaluate(predictionAndLabels_test_lr)\n",
    "\n",
    "print(\"Test accuracy = \" + str(test_accuracy_lr))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* What is your observations ? Write your oservations in the markdown format."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "There were some NA values in the data which we removed in processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "774"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 24. Perform the necessary tuning methods(2M)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.tuning import ParamGridBuilder, CrossValidator\n",
    "paramGrid = ParamGridBuilder()\\\n",
    "    .addGrid(lr.regParam, [0.1]) \\\n",
    "    .addGrid(lr.elasticNetParam, [0.5])\\\n",
    "    .build()\n",
    "    \n",
    "lr_crossval = CrossValidator(estimator=lr_Pipeline,\n",
    "                             estimatorParamMaps=paramGrid,\n",
    "                             evaluator=evaluator,\n",
    "                             numFolds=2)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run cross-validation, and choose the best set of parameters.\n",
    "lr_crossval_Model = lr_crossval.fit(trainingData)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_predictions_lrcv = lr_crossval_Model.transform(trainingData)\n",
    "test_predictions_lrcv = lr_crossval_Model.transform(testData)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train set accuracy  = 0.938664782975\n",
      "Test set accuracy = 0.940503192937\n"
     ]
    }
   ],
   "source": [
    "predictionAndLabels_train_lrcv = train_predictions_lrcv.select(\"prediction\", \"label\")\n",
    "train_accuracycv = evaluator.evaluate(predictionAndLabels_train_lrcv)\n",
    "print(\"Train set accuracy  = \" + str(train_accuracycv))\n",
    "\n",
    "predictionAndLabels_test_lrcv = test_predictions_lrcv.select(\"prediction\", \"label\")\n",
    "test_accuracycv = evaluator.evaluate(predictionAndLabels_test_lrcv)\n",
    "print(\"Test set accuracy = \" + str(test_accuracycv))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 25. Save the Crossvalidated model and load the model and pass the test data (7M)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# clusters.save(sc, \"/user/2305B47/BigDataCute/Model/kmeanModel\")\n",
    "# /user/2305B47/BigDataCute/Models\n",
    "lr_crossval_Model.bestModel.save(\"/user/2305B47/BigDataCute/Models/logi_model3\")\n",
    "## Go through the documentation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml import PipelineModel\n",
    "\n",
    "saved_model = PipelineModel.load(\"/user/2305B47/BigDataCute/Models/logi_model3\")\n",
    "# saved_model = lr_Pipeline_model.load(\"/user/2305B47/BigDataCute/Models/logi_model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set accuracy = 0.940503192937\n"
     ]
    }
   ],
   "source": [
    "test_predictions = saved_model.transform(testData)\n",
    "predictionAndLabels_test_lrcv = test_predictions.select(\"prediction\", \"label\")\n",
    "test_accuracycv = evaluator.evaluate(predictionAndLabels_test_lrcv)\n",
    "print(\"Test set accuracy = \" + str(test_accuracycv))\n",
    "# saved_model.transform(testData)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
